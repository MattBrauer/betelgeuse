rename(jd = JD,
error = uncert,
band = Band) %>%
filter(!is.na(mag)) %>%
distinct(jd, by, band, mag, error, .keep_all=TRUE)
}
load_file <- function(file) {
col_specs <- cols(
.default = col_character(),
JD = col_double(),
Magnitude = col_double(),
Uncertainty = col_double(),
Band = col_character(),
`Observer Code` = col_character(),
`Comment Code(s)` = col_character(),
`Validation Flag` = col_character(),
`Star Name` = col_character(),
`Measurement Method` = col_character(),
`Grouping Method` = col_skip(),
HJD = col_skip(),
HQuncertainty = col_skip()
)
read_csv(file, col_types = col_specs) %>%
rename(jd = JD,
by = `Observer Code`,
band = Band,
mag = Magnitude,
error = Uncertainty,
comCode = `Comment Code(s)`,
comment = Comments,
transformed = Transfomed,
airmass = Airmass,
obsAffil = `Observer Affiliation`,
mtype = `Measurement Method`,
starName = `Star Name`,
adsRef = `ADS Reference`,
digitizer = Digitizer,
credit = Credit,
cmag = Cmag,
kmag = Kmag,
val = `Validation Flag`,
compStar1 = `Comp Star 1`,
compStar2 = `Comp Star 2`,
charts = Charts) %>%
filter(!is.na(mag)) %>%
distinct(jd, by, band, mag, error, .keep_all=TRUE)
}
raw <- load_file(output_file_betelgeuse)
last_date <- raw %>%
arrange(desc(jd)) %>%
filter(row_number()==1) %>%
add_dates() %>%
pull(date)
new_data <- get_new_data(from_date=last_date)
### get latest data from AAVSO
## Note that their API returns data in different format than their web portal does!
get_new_data <- function(id='Betelgeuse', from_date='2010-01-01', to_date=today(), filename) {
col_specs <- cols(
.default = col_character(),
JD = col_double(),
mag = col_double(),
uncert = col_double(),
band = col_character(),
by = col_character(),
comCode = col_character(),
val = col_character(),
starName = col_character(),
mType = col_character(),
obsID = col_skip(),
fainterThan = col_skip(),
obsType = col_skip(),
software = col_skip(),
obsName = col_skip(),
obsCountry = col_skip()
)
fromjd <- JD(as.POSIXct(from_date))
tojd <- JD(as.POSIXct(to_date))
api_call <- paste0('https://www.aavso.org/vsx/index.php?view=api.delim&ident=%22',
id,
'%22&fromjd=',
fromjd,
'&tojd=',
tojd,
'&delimiter=@@@')
response <- GET(api_call)
new_data <- gsub("@@@", "\t", content(response))
new_data <- gsub("\r", "", new_data)
new_data %>%
read_tsv(col_types = col_specs) %>%
rename(jd = JD,
error = uncert) %>%
filter(!is.na(mag)) %>%
distinct(jd, by, band, mag, error, .keep_all=TRUE)
}
new_data <- get_new_data(from_date=last_date)
new_data
raw
knitr::opts_chunk$set(echo = FALSE)
library(tidyverse)
library(lubridate)
library(insol)
library(zoo)
library(forecast)
library(tsibble)
library(astrolibR)
library(httr)
## constants and files
files_betelgeuse <- c("data/aavso_betelgeuse_6.txt",
"data/aavso_betelgeuse_5.txt",
"data/aavso_betelgeuse_4.txt",
"data/aavso_betelgeuse_3.txt",
"data/aavso_betelgeuse_2.txt",
"data/aavso_betelgeuse_1.txt",
"data/aavso_betelgeuse_0.txt")
output_file_betelgeuse <- "data/aavso_betelgeuse.txt"
data_betelgeuse <- "data/aavso_betelgeuse.rds"
files_AC_Her <- "data/aavso_AC_Her.txt"
ra_betelgeuse <- list(h = 05, m = 55, s = 10.3)
### get latest data from AAVSO
## Note that their API returns data in different format than their web portal does!
get_new_data <- function(id='Betelgeuse', from_date='2010-01-01', to_date=today(), filename) {
col_specs <- cols(
.default = col_character(),
JD = col_double(),
mag = col_double(),
uncert = col_double(),
band = col_character(),
by = col_character(),
comCode = col_character(),
val = col_character(),
starName = col_character(),
mType = col_character(),
obsID = col_skip(),
fainterThan = col_skip(),
obsType = col_skip(),
software = col_skip(),
obsName = col_skip(),
obsCountry = col_skip()
)
fromjd <- JD(as.POSIXct(from_date))
tojd <- JD(as.POSIXct(to_date))
api_call <- paste0('https://www.aavso.org/vsx/index.php?view=api.delim&ident=%22',
id,
'%22&fromjd=',
fromjd,
'&tojd=',
tojd,
'&delimiter=@@@')
response <- GET(api_call)
new_data <- gsub("@@@", "\t", content(response))
new_data <- gsub("\r", "", new_data)
new_data %>%
read_tsv(col_types = col_specs) %>%
rename(jd = JD,
error = uncert) %>%
filter(!is.na(mag)) %>%
distinct(jd, by, band, mag, error, .keep_all=TRUE)
}
### transform h-m-s representation of RA into decimal days
ra2dec <- function(ra) {
ra$h + ra$m / 60 + ra$s / 3600
}
### add various representations of dates to tibble, including the sun's position relative to the target
add_dates <- function(magnitudes) {
magnitudes %>%
mutate(time = {if("jd" %in% names(.)) jd %% 1 else 0.5},
day = {if("jd" %in% names(.)) round(jd) else {if("day" %in% names(.)) day else NA}},
date = as_date(insol::JD(day, inverse = TRUE))) %>%
separate(date, into=c("year","month","dom"), remove=FALSE) %>%
mutate(year = as.integer(year),
month = as.integer(month),
dom = as.integer(dom),
doy = (insol::daydoy(year, month, dom) + 175) %% 365)
}
add_sunpos <- function(magnitudes, ra=ra_betelgeuse) {
magnitudes %>%
mutate(sun = sunpos(jd)$ra / 360,
sun_rel = (sun + 1 - ra2dec(ra)/24) %% 1,
sun_pos = sun_rel + time)
}
### create tibble from data files, combine and write combined to file
combine_files <- function(files, output_filename, dedup = TRUE) {
col_specs <- cols(.default = col_character())
file_contents <- do.call(rbind, lapply(as.list(files),
function(file) {
read_csv(file,
col_types = col_specs)
}))
if(dedup == TRUE) file_contents <- file_contents %>% distinct()
write_csv(file_contents, output_filename)
file_contents
}
### create tibble from data file, remove missing observations and rename some of the variables
load_file <- function(file) {
col_specs <- cols(
.default = col_character(),
JD = col_double(),
Magnitude = col_double(),
Uncertainty = col_double(),
Band = col_character(),
`Observer Code` = col_character(),
`Comment Code(s)` = col_character(),
`Validation Flag` = col_character(),
`Star Name` = col_character(),
`Measurement Method` = col_character(),
`Grouping Method` = col_skip(),
HJD = col_skip(),
HQuncertainty = col_skip()
)
read_csv(file, col_types = col_specs) %>%
rename(jd = JD,
by = `Observer Code`,
band = Band,
mag = Magnitude,
error = Uncertainty,
comCode = `Comment Code(s)`,
comment = Comments,
transformed = Transfomed,
airmass = Airmass,
obsAffil = `Observer Affiliation`,
mtype = `Measurement Method`,
starName = `Star Name`,
adsRef = `ADS Reference`,
digitizer = Digitizer,
credit = Credit,
cmag = Cmag,
kmag = Kmag,
val = `Validation Flag`,
compStar1 = `Comp Star 1`,
compStar2 = `Comp Star 2`,
charts = Charts) %>%
filter(!is.na(mag)) %>%
distinct(jd, by, band, mag, error, .keep_all=TRUE)
}
### average multiple simultaneous observations by observer
clean_data <- function(raw_data) {
raw_data %>%
select(jd, mag, observer, band) %>%
group_by(jd, observer, band) %>%
summarize(delta = max(mag) - min(mag), mag = mean(mag), n = n()) %>%
distinct() %>%
ungroup() %>%
select(jd, observer, band, mag, n, delta) %>%
arrange(jd)
}
### calculate average daily magnitude where day spans [0.5, 0.5)
daily_magnitude <- function(magnitudes) {
magnitudes %>%
mutate(day = round(jd)) %>%
select(day, mag, band, observer) %>%
group_by(band, observer, day) %>%
summarize(daily_observer_mag = mean(mag)) %>%
group_by(band, day) %>%
mutate(mean_daily_mag = mean(daily_observer_mag, na.rm=TRUE),
sd_daily_mag = sd(daily_observer_mag, na.rm=TRUE),
n_daily_mag = n(),
delta_daily_mag = (daily_observer_mag - mean_daily_mag)) %>%
ungroup() %>%
arrange(day)
}
combine_files(files_betelgeuse)
raw <- load_file(output_file_betelgeuse)
last_date <- raw %>%
arrange(desc(jd)) %>%
filter(row_number()==1) %>%
add_dates() %>%
pull(date)
raw <- get_new_data(from_date=last_date) %>%
bind_rows(raw)
raw
raw %>% distinct()
raw <- raw %>% distinct()
saveRDS(raw, file = data_betelgeuse)
cleaned <- clean_data(raw)
raw <- raw %>% rename(observer = by)
cleaned <- clean_data(raw)
cleaned
knitr::opts_chunk$set(echo = FALSE)
library(tidyverse)
library(lubridate)
library(insol)
library(zoo)
library(forecast)
library(tsibble)
library(astrolibR)
library(httr)
## constants and files
files_betelgeuse <- c("data/aavso_betelgeuse_6.txt",
"data/aavso_betelgeuse_5.txt",
"data/aavso_betelgeuse_4.txt",
"data/aavso_betelgeuse_3.txt",
"data/aavso_betelgeuse_2.txt",
"data/aavso_betelgeuse_1.txt",
"data/aavso_betelgeuse_0.txt")
output_file_betelgeuse <- "data/aavso_betelgeuse.txt"
data_betelgeuse <- "data/aavso_betelgeuse.rds"
files_AC_Her <- "data/aavso_AC_Her.txt"
ra_betelgeuse <- list(h = 05, m = 55, s = 10.3)
### get latest data from AAVSO
## Note that their API returns data in different format than their web portal does!
get_new_data <- function(id='Betelgeuse', from_date='2010-01-01', to_date=today(), filename) {
col_specs <- cols(
.default = col_character(),
JD = col_double(),
mag = col_double(),
uncert = col_double(),
band = col_character(),
by = col_character(),
comCode = col_character(),
val = col_character(),
starName = col_character(),
mType = col_character(),
obsID = col_skip(),
fainterThan = col_skip(),
obsType = col_skip(),
software = col_skip(),
obsName = col_skip(),
obsCountry = col_skip()
)
fromjd <- JD(as.POSIXct(from_date))
tojd <- JD(as.POSIXct(to_date))
api_call <- paste0('https://www.aavso.org/vsx/index.php?view=api.delim&ident=%22',
id,
'%22&fromjd=',
fromjd,
'&tojd=',
tojd,
'&delimiter=@@@')
response <- GET(api_call)
new_data <- gsub("@@@", "\t", content(response))
new_data <- gsub("\r", "", new_data)
new_data %>%
read_tsv(col_types = col_specs) %>%
rename(jd = JD,
observer = by,
error = uncert) %>%
filter(!is.na(mag)) %>%
distinct(jd, by, band, mag, error, .keep_all=TRUE)
}
### transform h-m-s representation of RA into decimal days
ra2dec <- function(ra) {
ra$h + ra$m / 60 + ra$s / 3600
}
### add various representations of dates to tibble, including the sun's position relative to the target
add_dates <- function(magnitudes) {
magnitudes %>%
mutate(time = {if("jd" %in% names(.)) jd %% 1 else 0.5},
day = {if("jd" %in% names(.)) round(jd) else {if("day" %in% names(.)) day else NA}},
date = as_date(insol::JD(day, inverse = TRUE))) %>%
separate(date, into=c("year","month","dom"), remove=FALSE) %>%
mutate(year = as.integer(year),
month = as.integer(month),
dom = as.integer(dom),
doy = (insol::daydoy(year, month, dom) + 175) %% 365)
}
add_sunpos <- function(magnitudes, ra=ra_betelgeuse) {
magnitudes %>%
mutate(sun = sunpos(jd)$ra / 360,
sun_rel = (sun + 1 - ra2dec(ra)/24) %% 1,
sun_pos = sun_rel + time)
}
### create tibble from data files, combine and write combined to file
combine_files <- function(files, output_filename, dedup = TRUE) {
col_specs <- cols(.default = col_character())
file_contents <- do.call(rbind, lapply(as.list(files),
function(file) {
read_csv(file,
col_types = col_specs)
}))
if(dedup == TRUE) file_contents <- file_contents %>% distinct()
write_csv(file_contents, output_filename)
file_contents
}
### create tibble from data file, remove missing observations and rename some of the variables
load_file <- function(file) {
col_specs <- cols(
.default = col_character(),
JD = col_double(),
Magnitude = col_double(),
Uncertainty = col_double(),
Band = col_character(),
`Observer Code` = col_character(),
`Comment Code(s)` = col_character(),
`Validation Flag` = col_character(),
`Star Name` = col_character(),
`Measurement Method` = col_character(),
`Grouping Method` = col_skip(),
HJD = col_skip(),
HQuncertainty = col_skip()
)
read_csv(file, col_types = col_specs) %>%
rename(jd = JD,
observer = `Observer Code`,
band = Band,
mag = Magnitude,
error = Uncertainty,
comCode = `Comment Code(s)`,
comment = Comments,
transformed = Transfomed,
airmass = Airmass,
obsAffil = `Observer Affiliation`,
mtype = `Measurement Method`,
starName = `Star Name`,
adsRef = `ADS Reference`,
digitizer = Digitizer,
credit = Credit,
cmag = Cmag,
kmag = Kmag,
val = `Validation Flag`,
compStar1 = `Comp Star 1`,
compStar2 = `Comp Star 2`,
charts = Charts) %>%
filter(!is.na(mag)) %>%
distinct(jd, by, band, mag, error, .keep_all=TRUE)
}
### average multiple simultaneous observations by observer
clean_data <- function(raw_data) {
raw_data %>%
select(jd, mag, observer, band) %>%
group_by(jd, observer, band) %>%
summarize(delta = max(mag) - min(mag), mag = mean(mag), n = n()) %>%
distinct() %>%
ungroup() %>%
select(jd, observer, band, mag, n, delta) %>%
arrange(jd)
}
### calculate average daily magnitude where day spans [0.5, 0.5)
daily_magnitude <- function(magnitudes) {
magnitudes %>%
mutate(day = round(jd)) %>%
select(day, mag, band, observer) %>%
group_by(band, observer, day) %>%
summarize(daily_observer_mag = mean(mag)) %>%
group_by(band, day) %>%
mutate(mean_daily_mag = mean(daily_observer_mag, na.rm=TRUE),
sd_daily_mag = sd(daily_observer_mag, na.rm=TRUE),
n_daily_mag = n(),
delta_daily_mag = (daily_observer_mag - mean_daily_mag)) %>%
ungroup() %>%
arrange(day)
}
daily_vis <- cleaned %>%
filter(band=="Vis.") %>%
daily_magnitude() %>%
select(-band) %>%
add_dates()
daily_v <- cleaned %>%
filter(band=="V") %>%
daily_magnitude() %>%
select(-band) %>%
add_dates()
daily_v %>% filter(date > '2010-01-01')
multiday <- daily_vis %>%
select(day, n_daily_mag) %>%
distinct() %>%
filter(n_daily_mag > 1) %>%
pull(day)
vis_ts <- cleaned %>%
filter(band=="Vis.") %>%
select(-band) %>%
as_tsibble(key = observer, index = jd, regular = FALSE)
v_ts <- cleaned %>%
filter(band=="V") %>%
select(-band) %>%
as_tsibble(key = observer, index = jd, regular = FALSE)
vvis_ts <- cleaned %>%
filter(band=="V" | band=="Vis.") %>%
as_tsibble(key = c(observer, band), index = jd, regular = FALSE)
daily_vis_ts <- daily_vis %>%
select(day, date, mean_daily_mag, sd_daily_mag, n_daily_mag) %>%
distinct() %>%
as_tsibble(key=NULL, index=day) %>%
fill_gaps() %>%
mutate(in_run = if_else(is.na(date), FALSE, TRUE),
last_of_run = lag(in_run, default = FALSE),
next_of_run = lead(in_run, default = FALSE),
run_break = in_run & !next_of_run) %>%
add_dates()
daily_v_ts <- daily_v %>%
select(day, date, mean_daily_mag, sd_daily_mag, n_daily_mag) %>%
distinct() %>%
as_tsibble(key=NULL, index=day) %>%
fill_gaps() %>%
mutate(in_run = if_else(is.na(date), FALSE, TRUE),
last_of_run = lag(in_run, default = FALSE),
next_of_run = lead(in_run, default = FALSE),
run_break = in_run & !next_of_run) %>%
add_dates()
daily_vis_ts %>% filter(date > '2010-01-01') %>% ggplot(aes(x=date, y=mean_daily_mag))
daily_vis_ts %>% filter(date > '2010-01-01') %>% ggplot(aes(x=date, y=mean_daily_mag)) + geom_point()
daily_vis_ts %>% filter(date > '2010-01-01') %>% ggplot(aes(x=date, y=mean_daily_mag)) + geom_point() + scale_y_reverse()
daily_v_ts %>% filter(date > '2010-01-01') %>% ggplot(aes(x=date, y=mean_daily_mag)) + geom_point() + scale_y_reverse()
daily_v_ts %>% filter(date > '2019-09-01') %>% ggplot(aes(x=date, y=mean_daily_mag)) + geom_point() + scale_y_reverse()
daily_v_ts %>% filter(date > '2019-06-01') %>% ggplot(aes(x=date, y=mean_daily_mag)) + geom_point() + scale_y_reverse()
daily_v_ts %>% filter(date > '2019-01-01') %>% ggplot(aes(x=date, y=mean_daily_mag)) + geom_point() + scale_y_reverse()
daily_vis_ts %>% filter(date > '2019-01-01') %>% ggplot(aes(x=date, y=mean_daily_mag)) + geom_point() + scale_y_reverse()
daily_vis_ts %>% filter(date > '2019-10-01') %>% ggplot(aes(x=date, y=mean_daily_mag)) + geom_point() + scale_y_reverse()
v_ts
vis_ts %>% filter(date > '2019-10-01') %>% ggplot(aes(x=date, y=mag)) + geom_point() + scale_y_reverse()
vis_ts %>% add_dates() %>% filter(date > '2019-10-01') %>% ggplot(aes(x=date, y=mag)) + geom_point() + scale_y_reverse()
vis_ts %>% add_dates() %>% filter(date > '2019-10-01', mag < 4) %>% ggplot(aes(x=date, y=mag)) + geom_point() + scale_y_reverse()
vis_ts %>% arrange(desc(jd))
vis_ts %>% add_dates() %>% filter(date > '2019-01-01', mag < 4) %>% ggplot(aes(x=date, y=mag)) + geom_point() + scale_y_reverse()
cleaned
cleaned %>% add_dates()
cleaned %>% add_dates() %>% arrange(desc(jd))
cleaned %>% add_dates() %>% filter(band=="Vis.") %>% arrange(desc(jd))
cleaned %>% add_dates() %>% filter(band=="V") %>% arrange(desc(jd))
cleaned %>% add_dates() %>% filter(band=="V", mag > 2) %>% arrange(desc(jd))
cleaned %>% add_dates() %>% filter(band=="Vis.", mag > 2) %>% arrange(desc(jd))
cleaned %>% add_dates() %>% filter(observer=="DPV") %>% arrange(desc(jd))
raw %>% add_dates() %>% filter(observer=="DPV") %>% arrange(desc(jd))
